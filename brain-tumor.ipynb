{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOWfgJZ00FYJkfGA392caZm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1HHdxo0uKK_","executionInfo":{"status":"ok","timestamp":1704630467616,"user_tz":-345,"elapsed":17793,"user":{"displayName":"tsu xAI","userId":"15796211830199997683"}},"outputId":"96beb8c8-3e0e-49d6-d99b-8c09ebafdaf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/projects/brain-tumor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNxu8BQtvsrn","executionInfo":{"status":"ok","timestamp":1704630469937,"user_tz":-345,"elapsed":10,"user":{"displayName":"tsu xAI","userId":"15796211830199997683"}},"outputId":"80f9c9cd-ac38-4f3d-bac2-ab304082cf7f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/projects/brain-tumor\n"]}]},{"cell_type":"code","source":["\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import numpy as np\n","import cv2\n","from glob import glob\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from unet import build_unet\n","from metrics import dice_loss, dice_coef\n","\n","\"\"\" Global parameters \"\"\"\n","H = 256\n","W = 256\n","\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def load_dataset(path, split=0.2):\n","    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n","    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n","\n","    split_size = int(len(images) * split)\n","\n","    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n","    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n","\n","    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n","    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n","\n","    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n","\n","def read_image(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_COLOR)\n","    x = cv2.resize(x, (W, H))\n","    x = x / 255.0\n","    x = x.astype(np.float32)\n","    return x\n","\n","def read_mask(path):\n","    path = path.decode()\n","    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n","    x = cv2.resize(x, (W, H))   ## (h, w)\n","    x = x / 255.0               ## (h, w)\n","    x = x.astype(np.float32)    ## (h, w)\n","    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n","    return x\n","\n","def tf_parse(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([H, W, 3])\n","    y.set_shape([H, W, 1])\n","    return x, y\n","\n","def tf_dataset(X, Y, batch=2):\n","    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n","    dataset = dataset.map(tf_parse)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(10)\n","    return dataset\n","\n","if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    \"\"\" Directory for storing files \"\"\"\n","    create_dir(\"files\")\n","\n","    \"\"\" Hyperparameters \"\"\"\n","    batch_size = 8\n","    lr = 1e-4\n","    num_epochs = 50\n","    model_path = os.path.join(\"files\", \"model.h5\")\n","    csv_path = os.path.join(\"files\", \"log.csv\")\n","\n","    \"\"\" Dataset \"\"\"\n","    dataset_path = \"/content/drive/MyDrive/projects/brain-tumor/dataset\"\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n","\n","    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n","    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n","    print(f\"Test : {len(test_x)} - {len(test_y)}\")\n","\n","    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n","    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n","\n","    \"\"\" Model \"\"\"\n","    model = build_unet((H, W, 3))\n","    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef])\n","\n","    callbacks = [\n","        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n","        CSVLogger(csv_path),\n","        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n","    ]\n","\n","    model.fit(\n","        train_dataset,\n","        epochs=num_epochs,\n","        validation_data=valid_dataset,\n","        callbacks=callbacks\n","    )"],"metadata":{"id":"_ud8jHVnwriR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704572591886,"user_tz":-345,"elapsed":7969985,"user":{"displayName":"tsu xAI","userId":"15796211830199997683"}},"outputId":"acc64d32-8310-4053-c09c-3b746b8acda8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 1840 - 1840\n","Valid: 612 - 612\n","Test : 612 - 612\n","Epoch 1/50\n","230/230 [==============================] - ETA: 0s - loss: 0.8129 - dice_coef: 0.1871\n","Epoch 1: val_loss improved from inf to 0.98481, saving model to files/model.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r230/230 [==============================] - 182s 623ms/step - loss: 0.8129 - dice_coef: 0.1871 - val_loss: 0.9848 - val_dice_coef: 0.0153 - lr: 1.0000e-04\n","Epoch 2/50\n","230/230 [==============================] - ETA: 0s - loss: 0.6533 - dice_coef: 0.3467\n","Epoch 2: val_loss improved from 0.98481 to 0.79888, saving model to files/model.h5\n","230/230 [==============================] - 145s 630ms/step - loss: 0.6533 - dice_coef: 0.3467 - val_loss: 0.7989 - val_dice_coef: 0.2013 - lr: 1.0000e-04\n","Epoch 3/50\n","230/230 [==============================] - ETA: 0s - loss: 0.5299 - dice_coef: 0.4701\n","Epoch 3: val_loss improved from 0.79888 to 0.49286, saving model to files/model.h5\n","230/230 [==============================] - 141s 612ms/step - loss: 0.5299 - dice_coef: 0.4701 - val_loss: 0.4929 - val_dice_coef: 0.5077 - lr: 1.0000e-04\n","Epoch 4/50\n","230/230 [==============================] - ETA: 0s - loss: 0.4341 - dice_coef: 0.5659\n","Epoch 4: val_loss improved from 0.49286 to 0.41371, saving model to files/model.h5\n","230/230 [==============================] - 139s 606ms/step - loss: 0.4341 - dice_coef: 0.5659 - val_loss: 0.4137 - val_dice_coef: 0.5862 - lr: 1.0000e-04\n","Epoch 5/50\n","230/230 [==============================] - ETA: 0s - loss: 0.3597 - dice_coef: 0.6403\n","Epoch 5: val_loss did not improve from 0.41371\n","230/230 [==============================] - 142s 615ms/step - loss: 0.3597 - dice_coef: 0.6403 - val_loss: 0.4253 - val_dice_coef: 0.5722 - lr: 1.0000e-04\n","Epoch 6/50\n","230/230 [==============================] - ETA: 0s - loss: 0.3159 - dice_coef: 0.6841\n","Epoch 6: val_loss improved from 0.41371 to 0.35512, saving model to files/model.h5\n","230/230 [==============================] - 149s 648ms/step - loss: 0.3159 - dice_coef: 0.6841 - val_loss: 0.3551 - val_dice_coef: 0.6450 - lr: 1.0000e-04\n","Epoch 7/50\n","230/230 [==============================] - ETA: 0s - loss: 0.2834 - dice_coef: 0.7166\n","Epoch 7: val_loss improved from 0.35512 to 0.34845, saving model to files/model.h5\n","230/230 [==============================] - 148s 642ms/step - loss: 0.2834 - dice_coef: 0.7166 - val_loss: 0.3484 - val_dice_coef: 0.6503 - lr: 1.0000e-04\n","Epoch 8/50\n","230/230 [==============================] - ETA: 0s - loss: 0.2652 - dice_coef: 0.7348\n","Epoch 8: val_loss improved from 0.34845 to 0.29030, saving model to files/model.h5\n","230/230 [==============================] - 147s 641ms/step - loss: 0.2652 - dice_coef: 0.7348 - val_loss: 0.2903 - val_dice_coef: 0.7106 - lr: 1.0000e-04\n","Epoch 9/50\n","230/230 [==============================] - ETA: 0s - loss: 0.2368 - dice_coef: 0.7632\n","Epoch 9: val_loss did not improve from 0.29030\n","230/230 [==============================] - 142s 617ms/step - loss: 0.2368 - dice_coef: 0.7632 - val_loss: 0.2972 - val_dice_coef: 0.7017 - lr: 1.0000e-04\n","Epoch 10/50\n","230/230 [==============================] - ETA: 0s - loss: 0.2254 - dice_coef: 0.7746\n","Epoch 10: val_loss did not improve from 0.29030\n","230/230 [==============================] - 135s 587ms/step - loss: 0.2254 - dice_coef: 0.7746 - val_loss: 0.2973 - val_dice_coef: 0.7018 - lr: 1.0000e-04\n","Epoch 11/50\n","230/230 [==============================] - ETA: 0s - loss: 0.2144 - dice_coef: 0.7856\n","Epoch 11: val_loss improved from 0.29030 to 0.28869, saving model to files/model.h5\n","230/230 [==============================] - 148s 642ms/step - loss: 0.2144 - dice_coef: 0.7856 - val_loss: 0.2887 - val_dice_coef: 0.7110 - lr: 1.0000e-04\n","Epoch 12/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1996 - dice_coef: 0.8004\n","Epoch 12: val_loss did not improve from 0.28869\n","230/230 [==============================] - 135s 586ms/step - loss: 0.1996 - dice_coef: 0.8004 - val_loss: 0.3575 - val_dice_coef: 0.6413 - lr: 1.0000e-04\n","Epoch 13/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1914 - dice_coef: 0.8086\n","Epoch 13: val_loss improved from 0.28869 to 0.26136, saving model to files/model.h5\n","230/230 [==============================] - 149s 647ms/step - loss: 0.1914 - dice_coef: 0.8086 - val_loss: 0.2614 - val_dice_coef: 0.7383 - lr: 1.0000e-04\n","Epoch 14/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1893 - dice_coef: 0.8107\n","Epoch 14: val_loss improved from 0.26136 to 0.25424, saving model to files/model.h5\n","230/230 [==============================] - 152s 662ms/step - loss: 0.1893 - dice_coef: 0.8107 - val_loss: 0.2542 - val_dice_coef: 0.7454 - lr: 1.0000e-04\n","Epoch 15/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1727 - dice_coef: 0.8273\n","Epoch 15: val_loss did not improve from 0.25424\n","230/230 [==============================] - 143s 619ms/step - loss: 0.1727 - dice_coef: 0.8273 - val_loss: 0.2609 - val_dice_coef: 0.7388 - lr: 1.0000e-04\n","Epoch 16/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1682 - dice_coef: 0.8318\n","Epoch 16: val_loss improved from 0.25424 to 0.24147, saving model to files/model.h5\n","230/230 [==============================] - 150s 654ms/step - loss: 0.1682 - dice_coef: 0.8318 - val_loss: 0.2415 - val_dice_coef: 0.7581 - lr: 1.0000e-04\n","Epoch 17/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1531 - dice_coef: 0.8469\n","Epoch 17: val_loss did not improve from 0.24147\n","230/230 [==============================] - 135s 586ms/step - loss: 0.1531 - dice_coef: 0.8469 - val_loss: 0.2608 - val_dice_coef: 0.7389 - lr: 1.0000e-04\n","Epoch 18/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1565 - dice_coef: 0.8435\n","Epoch 18: val_loss did not improve from 0.24147\n","230/230 [==============================] - 135s 585ms/step - loss: 0.1565 - dice_coef: 0.8435 - val_loss: 0.2696 - val_dice_coef: 0.7302 - lr: 1.0000e-04\n","Epoch 19/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1563 - dice_coef: 0.8437\n","Epoch 19: val_loss did not improve from 0.24147\n","230/230 [==============================] - 142s 616ms/step - loss: 0.1563 - dice_coef: 0.8437 - val_loss: 0.2417 - val_dice_coef: 0.7584 - lr: 1.0000e-04\n","Epoch 20/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1566 - dice_coef: 0.8434\n","Epoch 20: val_loss improved from 0.24147 to 0.22211, saving model to files/model.h5\n","230/230 [==============================] - 149s 649ms/step - loss: 0.1566 - dice_coef: 0.8434 - val_loss: 0.2221 - val_dice_coef: 0.7785 - lr: 1.0000e-04\n","Epoch 21/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1434 - dice_coef: 0.8566\n","Epoch 21: val_loss did not improve from 0.22211\n","230/230 [==============================] - 141s 613ms/step - loss: 0.1434 - dice_coef: 0.8566 - val_loss: 0.2226 - val_dice_coef: 0.7770 - lr: 1.0000e-04\n","Epoch 22/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1420 - dice_coef: 0.8580\n","Epoch 22: val_loss did not improve from 0.22211\n","230/230 [==============================] - 135s 588ms/step - loss: 0.1420 - dice_coef: 0.8580 - val_loss: 0.2262 - val_dice_coef: 0.7735 - lr: 1.0000e-04\n","Epoch 23/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1336 - dice_coef: 0.8664\n","Epoch 23: val_loss did not improve from 0.22211\n","230/230 [==============================] - 142s 616ms/step - loss: 0.1336 - dice_coef: 0.8664 - val_loss: 0.3058 - val_dice_coef: 0.6907 - lr: 1.0000e-04\n","Epoch 24/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1301 - dice_coef: 0.8699\n","Epoch 24: val_loss improved from 0.22211 to 0.22121, saving model to files/model.h5\n","230/230 [==============================] - 140s 608ms/step - loss: 0.1301 - dice_coef: 0.8699 - val_loss: 0.2212 - val_dice_coef: 0.7783 - lr: 1.0000e-04\n","Epoch 25/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1181 - dice_coef: 0.8819\n","Epoch 25: val_loss did not improve from 0.22121\n","230/230 [==============================] - 135s 586ms/step - loss: 0.1181 - dice_coef: 0.8819 - val_loss: 0.2448 - val_dice_coef: 0.7536 - lr: 1.0000e-04\n","Epoch 26/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1375 - dice_coef: 0.8625\n","Epoch 26: val_loss did not improve from 0.22121\n","230/230 [==============================] - 135s 586ms/step - loss: 0.1375 - dice_coef: 0.8625 - val_loss: 0.2259 - val_dice_coef: 0.7733 - lr: 1.0000e-04\n","Epoch 27/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1248 - dice_coef: 0.8752\n","Epoch 27: val_loss improved from 0.22121 to 0.21575, saving model to files/model.h5\n","230/230 [==============================] - 149s 649ms/step - loss: 0.1248 - dice_coef: 0.8752 - val_loss: 0.2157 - val_dice_coef: 0.7834 - lr: 1.0000e-04\n","Epoch 28/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1265 - dice_coef: 0.8735\n","Epoch 28: val_loss did not improve from 0.21575\n","230/230 [==============================] - 135s 587ms/step - loss: 0.1265 - dice_coef: 0.8735 - val_loss: 0.2294 - val_dice_coef: 0.7710 - lr: 1.0000e-04\n","Epoch 29/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1194 - dice_coef: 0.8806\n","Epoch 29: val_loss improved from 0.21575 to 0.21330, saving model to files/model.h5\n","230/230 [==============================] - 153s 664ms/step - loss: 0.1194 - dice_coef: 0.8806 - val_loss: 0.2133 - val_dice_coef: 0.7863 - lr: 1.0000e-04\n","Epoch 30/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1172 - dice_coef: 0.8828\n","Epoch 30: val_loss did not improve from 0.21330\n","230/230 [==============================] - 142s 617ms/step - loss: 0.1172 - dice_coef: 0.8828 - val_loss: 0.2324 - val_dice_coef: 0.7675 - lr: 1.0000e-04\n","Epoch 31/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1155 - dice_coef: 0.8845\n","Epoch 31: val_loss did not improve from 0.21330\n","230/230 [==============================] - 135s 586ms/step - loss: 0.1155 - dice_coef: 0.8845 - val_loss: 0.2171 - val_dice_coef: 0.7827 - lr: 1.0000e-04\n","Epoch 32/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1067 - dice_coef: 0.8933\n","Epoch 32: val_loss did not improve from 0.21330\n","230/230 [==============================] - 142s 617ms/step - loss: 0.1067 - dice_coef: 0.8933 - val_loss: 0.2330 - val_dice_coef: 0.7661 - lr: 1.0000e-04\n","Epoch 33/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1104 - dice_coef: 0.8896\n","Epoch 33: val_loss improved from 0.21330 to 0.19639, saving model to files/model.h5\n","230/230 [==============================] - 151s 658ms/step - loss: 0.1104 - dice_coef: 0.8896 - val_loss: 0.1964 - val_dice_coef: 0.8030 - lr: 1.0000e-04\n","Epoch 34/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0969 - dice_coef: 0.9031\n","Epoch 34: val_loss improved from 0.19639 to 0.19532, saving model to files/model.h5\n","230/230 [==============================] - 143s 623ms/step - loss: 0.0969 - dice_coef: 0.9031 - val_loss: 0.1953 - val_dice_coef: 0.8052 - lr: 1.0000e-04\n","Epoch 35/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0985 - dice_coef: 0.9015\n","Epoch 35: val_loss did not improve from 0.19532\n","230/230 [==============================] - 142s 617ms/step - loss: 0.0985 - dice_coef: 0.9015 - val_loss: 0.2091 - val_dice_coef: 0.7909 - lr: 1.0000e-04\n","Epoch 36/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1072 - dice_coef: 0.8928\n","Epoch 36: val_loss did not improve from 0.19532\n","230/230 [==============================] - 135s 588ms/step - loss: 0.1072 - dice_coef: 0.8928 - val_loss: 0.2650 - val_dice_coef: 0.7344 - lr: 1.0000e-04\n","Epoch 37/50\n","230/230 [==============================] - ETA: 0s - loss: 0.1060 - dice_coef: 0.8940\n","Epoch 37: val_loss did not improve from 0.19532\n","230/230 [==============================] - 142s 617ms/step - loss: 0.1060 - dice_coef: 0.8940 - val_loss: 0.2200 - val_dice_coef: 0.7802 - lr: 1.0000e-04\n","Epoch 38/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0997 - dice_coef: 0.9003\n","Epoch 38: val_loss improved from 0.19532 to 0.19093, saving model to files/model.h5\n","230/230 [==============================] - 149s 649ms/step - loss: 0.0997 - dice_coef: 0.9003 - val_loss: 0.1909 - val_dice_coef: 0.8097 - lr: 1.0000e-04\n","Epoch 39/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0864 - dice_coef: 0.9136\n","Epoch 39: val_loss improved from 0.19093 to 0.18933, saving model to files/model.h5\n","230/230 [==============================] - 149s 650ms/step - loss: 0.0864 - dice_coef: 0.9136 - val_loss: 0.1893 - val_dice_coef: 0.8106 - lr: 1.0000e-04\n","Epoch 40/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0806 - dice_coef: 0.9194\n","Epoch 40: val_loss improved from 0.18933 to 0.18440, saving model to files/model.h5\n","230/230 [==============================] - 146s 633ms/step - loss: 0.0806 - dice_coef: 0.9194 - val_loss: 0.1844 - val_dice_coef: 0.8154 - lr: 1.0000e-04\n","Epoch 41/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0774 - dice_coef: 0.9226\n","Epoch 41: val_loss did not improve from 0.18440\n","230/230 [==============================] - 136s 591ms/step - loss: 0.0774 - dice_coef: 0.9226 - val_loss: 0.1921 - val_dice_coef: 0.8076 - lr: 1.0000e-04\n","Epoch 42/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0788 - dice_coef: 0.9212\n","Epoch 42: val_loss did not improve from 0.18440\n","230/230 [==============================] - 135s 586ms/step - loss: 0.0788 - dice_coef: 0.9212 - val_loss: 0.1956 - val_dice_coef: 0.8043 - lr: 1.0000e-04\n","Epoch 43/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0743 - dice_coef: 0.9257\n","Epoch 43: val_loss did not improve from 0.18440\n","230/230 [==============================] - 142s 618ms/step - loss: 0.0743 - dice_coef: 0.9257 - val_loss: 0.1880 - val_dice_coef: 0.8118 - lr: 1.0000e-04\n","Epoch 44/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0738 - dice_coef: 0.9262\n","Epoch 44: val_loss did not improve from 0.18440\n","230/230 [==============================] - 135s 588ms/step - loss: 0.0738 - dice_coef: 0.9262 - val_loss: 0.1931 - val_dice_coef: 0.8069 - lr: 1.0000e-04\n","Epoch 45/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0761 - dice_coef: 0.9239\n","Epoch 45: val_loss did not improve from 0.18440\n","\n","Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n","230/230 [==============================] - 142s 616ms/step - loss: 0.0761 - dice_coef: 0.9239 - val_loss: 0.2207 - val_dice_coef: 0.7791 - lr: 1.0000e-04\n","Epoch 46/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0729 - dice_coef: 0.9271\n","Epoch 46: val_loss did not improve from 0.18440\n","230/230 [==============================] - 135s 588ms/step - loss: 0.0729 - dice_coef: 0.9271 - val_loss: 0.1867 - val_dice_coef: 0.8128 - lr: 1.0000e-05\n","Epoch 47/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0654 - dice_coef: 0.9346\n","Epoch 47: val_loss did not improve from 0.18440\n","230/230 [==============================] - 135s 587ms/step - loss: 0.0654 - dice_coef: 0.9346 - val_loss: 0.1859 - val_dice_coef: 0.8137 - lr: 1.0000e-05\n","Epoch 48/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0627 - dice_coef: 0.9373\n","Epoch 48: val_loss did not improve from 0.18440\n","230/230 [==============================] - 135s 588ms/step - loss: 0.0627 - dice_coef: 0.9373 - val_loss: 0.1848 - val_dice_coef: 0.8148 - lr: 1.0000e-05\n","Epoch 49/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0610 - dice_coef: 0.9390\n","Epoch 49: val_loss did not improve from 0.18440\n","230/230 [==============================] - 142s 617ms/step - loss: 0.0610 - dice_coef: 0.9390 - val_loss: 0.1856 - val_dice_coef: 0.8140 - lr: 1.0000e-05\n","Epoch 50/50\n","230/230 [==============================] - ETA: 0s - loss: 0.0596 - dice_coef: 0.9404\n","Epoch 50: val_loss did not improve from 0.18440\n","\n","Epoch 50: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n","230/230 [==============================] - 135s 588ms/step - loss: 0.0596 - dice_coef: 0.9404 - val_loss: 0.1856 - val_dice_coef: 0.8140 - lr: 1.0000e-05\n"]}]},{"cell_type":"code","source":["\n","import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import numpy as np\n","import cv2\n","import pandas as pd\n","from glob import glob\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.utils import CustomObjectScope\n","from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from metrics import dice_loss, dice_coef\n","from train import load_dataset\n","from unet import build_unet\n","\n","\"\"\" Global parameters \"\"\"\n","H = 256\n","W = 256\n","\n","\"\"\" Creating a directory \"\"\"\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def save_results(image, mask, y_pred, save_image_path):\n","    mask = np.expand_dims(mask, axis=-1)\n","    mask = np.concatenate([mask, mask, mask], axis=-1)\n","\n","    y_pred = np.expand_dims(y_pred, axis=-1)\n","    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n","    y_pred = y_pred * 255\n","\n","    line = np.ones((H, 10, 3)) * 255\n","\n","    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n","    cv2.imwrite(save_image_path, cat_images)\n","\n","\n","if __name__ == \"__main__\":\n","    \"\"\" Seeding \"\"\"\n","    np.random.seed(42)\n","    tf.random.set_seed(42)\n","\n","    \"\"\" Directory for storing files \"\"\"\n","    create_dir(\"results\")\n","\n","    \"\"\" Load the model \"\"\"\n","    with CustomObjectScope({\"dice_coef\": dice_coef, \"dice_loss\": dice_loss}):\n","        model = tf.keras.models.load_model(os.path.join(\"files\", \"model.h5\"))\n","\n","    \"\"\" Dataset \"\"\"\n","    dataset_path = \"/content/drive/MyDrive/projects/brain-tumor/dataset\"\n","    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n","\n","    \"\"\" Prediction and Evaluation \"\"\"\n","    SCORE = []\n","    for x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n","        \"\"\" Extracting the name \"\"\"\n","        name = x.split(\"/\")[-1]\n","\n","        \"\"\" Reading the image \"\"\"\n","        image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n","        image = cv2.resize(image, (W, H))       ## [H, w, 3]\n","        x = image/255.0                         ## [H, w, 3]\n","        x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n","\n","        \"\"\" Reading the mask \"\"\"\n","        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n","        mask = cv2.resize(mask, (W, H))\n","\n","        \"\"\" Prediction \"\"\"\n","        y_pred = model.predict(x, verbose=0)[0]\n","        y_pred = np.squeeze(y_pred, axis=-1)\n","        y_pred = y_pred >= 0.5\n","        y_pred = y_pred.astype(np.int32)\n","\n","        \"\"\" Saving the prediction \"\"\"\n","        save_image_path = os.path.join(\"results\", name)\n","        save_results(image, mask, y_pred, save_image_path)\n","\n","        \"\"\" Flatten the array \"\"\"\n","        mask = mask/255.0\n","        mask = (mask > 0.5).astype(np.int32).flatten()\n","        y_pred = y_pred.flatten()\n","\n","        \"\"\" Calculating the metrics values \"\"\"\n","        f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n","        jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n","        recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n","        precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n","        SCORE.append([name, f1_value, jac_value, recall_value, precision_value])\n","\n","    \"\"\" Metrics values \"\"\"\n","    score = [s[1:]for s in SCORE]\n","    score = np.mean(score, axis=0)\n","    print(f\"F1: {score[0]:0.5f}\")\n","    print(f\"Jaccard: {score[1]:0.5f}\")\n","    print(f\"Recall: {score[2]:0.5f}\")\n","    print(f\"Precision: {score[3]:0.5f}\")\n","\n","    df = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n","    df.to_csv(\"files/score.csv\")"],"metadata":{"id":"04SUotrqx8lM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704631217012,"user_tz":-345,"elapsed":428855,"user":{"displayName":"tsu xAI","userId":"15796211830199997683"}},"outputId":"cb833bdf-1c07-45a7-eab9-3b27d358a695"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 612/612 [06:25<00:00,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["F1: 0.75845\n","Jaccard: 0.67126\n","Recall: 0.77457\n","Precision: 0.79887\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"5BuoSedDGyqi","executionInfo":{"status":"ok","timestamp":1704618218943,"user_tz":-345,"elapsed":12,"user":{"displayName":"tsu xAI","userId":"15796211830199997683"}},"outputId":"9dfafe49-ed3f-4151-d312-c88518f7cce3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/projects/brain-tumor'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"9TpVBVX3KJ9F"},"execution_count":null,"outputs":[]}]}